/*
 * Licensed to Elasticsearch under one or more contributor
 * license agreements. See the NOTICE file distributed with
 * this work for additional information regarding copyright
 * ownership. Elasticsearch licenses this file to you under
 * the Apache License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

//apply plugin: 'nebula.provided-base'
 
esplugin {
  description 'The HDFS repository plugin adds support for Hadoop Distributed File-System (HDFS) repositories.'
  classname 'org.elasticsearch.plugin.hadoop.hdfs.HdfsPlugin'
}

configurations {
    hadoop1
    hadoop2
}

versions << [
  'hadoop1': '1.2.1',
  'hadoop2': '2.7.1'
]

dependencies {
  provided "org.elasticsearch:elasticsearch:${versions.elasticsearch}"
  provided "org.apache.hadoop:hadoop-core:${versions.hadoop1}"

  // use Hadoop1 to compile and test things (a subset of Hadoop2)
  testCompile "org.apache.hadoop:hadoop-core:${versions.hadoop1}"
  testCompile "org.apache.hadoop:hadoop-test:${versions.hadoop1}"
  // Hadoop dependencies
  testCompile "commons-configuration:commons-configuration:1.6"
  testCompile "commons-lang:commons-lang:${versions.commonslang}"
  testCompile "commons-collections:commons-collections:3.2.2"
  testCompile "commons-net:commons-net:1.4.1"
  testCompile "org.mortbay.jetty:jetty:6.1.26"
  testCompile "org.mortbay.jetty:jetty-util:6.1.26"
  testCompile "org.mortbay.jetty:servlet-api:2.5-20081211"
  testCompile "com.sun.jersey:jersey-core:1.8"
  

  hadoop1("org.apache.hadoop:hadoop-core:${versions.hadoop1}") {
    exclude module: "commons-cli"
    exclude group: "com.sun.jersey"
    exclude group: "org.mortbay.jetty"
    exclude group: "tomcat"
    exclude module: "commons-el"
    exclude module: "hsqldb"
    exclude group: "org.eclipse.jdt"
    exclude module: "commons-beanutils"
    exclude module: "commons-beanutils-core"
    exclude module: "junit"
    // provided by ES itself
    exclude group: "log4j"
  }

  hadoop2("org.apache.hadoop:hadoop-client:${versions.hadoop2}") {
    exclude module: "commons-cli"
    exclude group: "com.sun.jersey"
    exclude group: "com.sun.jersey.contribs"
    exclude group: "com.sun.jersey.jersey-test-framework"
    exclude module: "guice"
    exclude group: "org.mortbay.jetty"
    exclude group: "tomcat"
    exclude module: "commons-el"
    exclude module: "hsqldb"
    exclude group: "org.eclipse.jdt"
    exclude module: "commons-beanutils"
    exclude module: "commons-beanutils-core"
    exclude module: "javax.servlet"
    exclude module: "junit"
    // provided by ES itself
    exclude group: "log4j"
  }

  hadoop2("org.apache.hadoop:hadoop-hdfs:${versions.hadoop2}") {
    exclude module: "guava"
    exclude module: "junit"
    // provided by ES itself
    exclude group: "log4j"
  }
} 

configurations.all {
    resolutionStrategy {
        force "commons-codec:commons-codec:${versions.commonscodec}"
        force "commons-logging:commons-logging:${versions.commonslogging}"
        force "commons-lang:commons-lang:2.6"
        force "commons-httpclient:commons-httpclient:3.0.1"
        force "org.codehaus.jackson:jackson-core-asl:1.8.8"
        force "org.codehaus.jackson:jackson-mapper-asl:1.8.8"
        force "com.google.code.findbugs:jsr305:3.0.0"
        force "com.google.guava:guava:16.0.1"
        force "org.slf4j:slf4j-api:1.7.10"
        force "org.slf4j:slf4j-log4j12:1.7.10"
    }
}


dependencyLicenses {
  mapping from: /hadoop-core.*/, to: 'hadoop-1'
  mapping from: /hadoop-.*/, to: 'hadoop-2'
}

compileJava.options.compilerArgs << '-Xlint:-deprecation,-rawtypes'

// main jar includes just the plugin classes
jar {
    include "org/elasticsearch/plugin/hadoop/hdfs/*"
}

// hadoop jar (which actually depend on Hadoop)
task hadoopLinkedJar(type: Jar, dependsOn:jar) {
    appendix "internal"
    from sourceSets.main.output.classesDir
    // exclude plugin
    exclude "org/elasticsearch/plugin/hadoop/hdfs/*"
}


bundlePlugin.dependsOn hadoopLinkedJar

// configure 'bundle' as being w/o Hadoop deps
bundlePlugin {
    into ("internal-libs") {
        from hadoopLinkedJar.archivePath
    }
    
    into ("hadoop-libs") {
        from configurations.hadoop2.allArtifacts.files
        from configurations.hadoop2
    }
}


task distZipHadoop1(type: Zip, dependsOn: [hadoopLinkedJar, jar]) { zipTask ->
    from (zipTree(bundlePlugin.archivePath)) {
        include "*"
        include "internal-libs/**"
    }
    
    description = "Builds archive (with Hadoop1 dependencies) suitable for download page."
    classifier = "hadoop1"

    into ("hadoop-libs") {
        from configurations.hadoop1.allArtifacts.files
        from configurations.hadoop1
    }
}

task distZipHadoop2(type: Zip, dependsOn: [hadoopLinkedJar, jar]) { zipTask ->
    from (zipTree(bundlePlugin.archivePath)) {
        include "*"
        include "internal-libs/**"
    }
        
    description = "Builds archive (with Hadoop2/YARN dependencies) suitable for download page."
    classifier = "hadoop2"

    into ("hadoop-libs") {
        from configurations.hadoop2.allArtifacts.files
        from configurations.hadoop2
    }
}

task distZipNoHadoop(type: Zip, dependsOn: [hadoopLinkedJar, jar]) { zipTask ->
    from (zipTree(bundlePlugin.archivePath)) {
        exclude "hadoop-libs/**"
    }
    
    from sourceSets.main.output.resourcesDir

    description = "Builds archive (without any Hadoop dependencies) suitable for download page."
    classifier = "lite"
}


artifacts {
    archives bundlePlugin
    'default' bundlePlugin
    archives distZipHadoop1
    archives distZipHadoop2
    archives distZipNoHadoop
}

integTest {
    cluster {
        plugin(pluginProperties.extension.name, zipTree(distZipHadoop2.archivePath))
    }
}

thirdPartyAudit.excludes = [
  // classes are missing
  'javax.mail.internet.MimeMultipart', 
  'javax.mail.util.ByteArrayDataSource', 
  'org.apache.commons.beanutils.BeanUtils', 
  'org.apache.commons.beanutils.DynaBean', 
  'org.apache.commons.beanutils.DynaClass', 
  'org.apache.commons.beanutils.DynaProperty', 
  'org.apache.commons.beanutils.PropertyUtils', 
  'org.apache.commons.digester.AbstractObjectCreationFactory', 
  'org.apache.commons.digester.CallMethodRule', 
  'org.apache.commons.digester.Digester', 
  'org.apache.commons.digester.ObjectCreationFactory', 
  'org.apache.commons.digester.substitution.MultiVariableExpander', 
  'org.apache.commons.digester.substitution.VariableSubstitutor', 
  'org.apache.commons.digester.xmlrules.DigesterLoader', 
  'org.apache.commons.httpclient.Header', 
  'org.apache.commons.httpclient.HttpClient', 
  'org.apache.commons.httpclient.methods.GetMethod', 
  'org.apache.commons.jxpath.JXPathContext', 
  'org.apache.commons.jxpath.ri.JXPathContextReferenceImpl', 
  'org.apache.commons.jxpath.ri.QName', 
  'org.apache.commons.jxpath.ri.compiler.NodeNameTest', 
  'org.apache.commons.jxpath.ri.compiler.NodeTest', 
  'org.apache.commons.jxpath.ri.compiler.NodeTypeTest', 
  'org.apache.commons.jxpath.ri.model.NodeIterator', 
  'org.apache.commons.jxpath.ri.model.NodePointer', 
  'org.apache.commons.jxpath.ri.model.NodePointerFactory', 
  'org.apache.ftpserver.DefaultFtpServerContext', 
  'org.apache.ftpserver.FtpServer', 
  'org.apache.ftpserver.ftplet.Authority', 
  'org.apache.ftpserver.ftplet.UserManager', 
  'org.apache.ftpserver.interfaces.FtpServerContext', 
  'org.apache.ftpserver.listener.mina.MinaListener', 
  'org.apache.ftpserver.usermanager.BaseUser', 
  'org.apache.ftpserver.usermanager.WritePermission', 
  'org.apache.hadoop.examples.DBCountPageView', 
  'org.apache.hadoop.examples.PiEstimator', 
  'org.apache.hadoop.examples.RandomWriter', 
  'org.apache.hadoop.examples.SecondarySort$FirstGroupingComparator', 
  'org.apache.hadoop.examples.SecondarySort$FirstPartitioner', 
  'org.apache.hadoop.examples.SecondarySort$IntPair', 
  'org.apache.hadoop.examples.SecondarySort$MapClass', 
  'org.apache.hadoop.examples.SecondarySort$Reduce', 
  'org.apache.hadoop.examples.SleepJob$SleepInputFormat', 
  'org.apache.hadoop.examples.SleepJob', 
  'org.apache.hadoop.examples.Sort', 
  'org.apache.hadoop.examples.WordCount$IntSumReducer', 
  'org.apache.hadoop.examples.WordCount$TokenizerMapper', 
  'org.apache.hadoop.examples.WordCount', 
  'org.apache.hadoop.tools.DistCh', 
  'org.apache.hadoop.tools.DistCp', 
  'org.apache.hadoop.tools.HadoopArchives', 
  'org.apache.hadoop.tools.distcp2.CopyListing', 
  'org.apache.hadoop.tools.distcp2.DistCp', 
  'org.apache.hadoop.tools.distcp2.DistCpOptionSwitch', 
  'org.apache.hadoop.tools.distcp2.DistCpOptions$FileAttribute', 
  'org.apache.hadoop.tools.distcp2.DistCpOptions', 
  'org.apache.hadoop.tools.distcp2.FileBasedCopyListing', 
  'org.apache.hadoop.tools.distcp2.GlobbedCopyListing', 
  'org.apache.hadoop.tools.distcp2.OptionsParser', 
  'org.apache.hadoop.tools.distcp2.SimpleCopyListing', 
  'org.apache.hadoop.tools.distcp2.mapred.CopyCommitter', 
  'org.apache.hadoop.tools.distcp2.mapred.CopyMapper$Counter', 
  'org.apache.hadoop.tools.distcp2.mapred.CopyMapper', 
  'org.apache.hadoop.tools.distcp2.mapred.CopyOutputFormat', 
  'org.apache.hadoop.tools.distcp2.mapred.UniformSizeInputFormat', 
  'org.apache.hadoop.tools.distcp2.mapred.lib.DynamicInputFormat', 
  'org.apache.hadoop.tools.distcp2.util.DistCpUtils', 
  'org.apache.hadoop.tools.distcp2.util.RetriableCommand', 
  'org.apache.hadoop.tools.distcp2.util.ThrottledInputStream', 
  'org.apache.hadoop.tools.rumen.CDFPiecewiseLinearRandomGenerator', 
  'org.apache.hadoop.tools.rumen.CDFRandomGenerator', 
  'org.apache.hadoop.tools.rumen.DeepCompare', 
  'org.apache.hadoop.tools.rumen.DeepInequalityException', 
  'org.apache.hadoop.tools.rumen.DefaultInputDemuxer', 
  'org.apache.hadoop.tools.rumen.EventType', 
  'org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer', 
  'org.apache.hadoop.tools.rumen.Histogram', 
  'org.apache.hadoop.tools.rumen.HistoryEvent', 
  'org.apache.hadoop.tools.rumen.InputDemuxer', 
  'org.apache.hadoop.tools.rumen.JobBuilder', 
  'org.apache.hadoop.tools.rumen.JobConfPropertyNames', 
  'org.apache.hadoop.tools.rumen.JobConfigurationParser', 
  'org.apache.hadoop.tools.rumen.JobHistoryParser', 
  'org.apache.hadoop.tools.rumen.JobHistoryParserFactory', 
  'org.apache.hadoop.tools.rumen.JobStory', 
  'org.apache.hadoop.tools.rumen.JobTraceReader', 
  'org.apache.hadoop.tools.rumen.JsonObjectMapperParser', 
  'org.apache.hadoop.tools.rumen.LogRecordType', 
  'org.apache.hadoop.tools.rumen.LoggedDiscreteCDF', 
  'org.apache.hadoop.tools.rumen.LoggedJob', 
  'org.apache.hadoop.tools.rumen.LoggedNetworkTopology', 
  'org.apache.hadoop.tools.rumen.LoggedSingleRelativeRanking', 
  'org.apache.hadoop.tools.rumen.LoggedTask', 
  'org.apache.hadoop.tools.rumen.LoggedTaskAttempt', 
  'org.apache.hadoop.tools.rumen.Pair', 
  'org.apache.hadoop.tools.rumen.ParsedJob', 
  'org.apache.hadoop.tools.rumen.ParsedLine', 
  'org.apache.hadoop.tools.rumen.ParsedTask', 
  'org.apache.hadoop.tools.rumen.ParsedTaskAttempt', 
  'org.apache.hadoop.tools.rumen.PossiblyDecompressedInputStream', 
  'org.apache.hadoop.tools.rumen.Pre21JobHistoryConstants$Values', 
  'org.apache.hadoop.tools.rumen.RandomSeedGenerator', 
  'org.apache.hadoop.tools.rumen.ResourceUsageMetrics', 
  'org.apache.hadoop.tools.rumen.RewindableInputStream', 
  'org.apache.hadoop.tools.rumen.TaskAttemptFinishedEvent', 
  'org.apache.hadoop.tools.rumen.TaskAttemptInfo', 
  'org.apache.hadoop.tools.rumen.TaskAttemptUnsuccessfulCompletionEvent', 
  'org.apache.hadoop.tools.rumen.TaskInfo', 
  'org.apache.hadoop.tools.rumen.TaskStartedEvent', 
  'org.apache.hadoop.tools.rumen.TopologyBuilder', 
  'org.apache.hadoop.tools.rumen.TraceBuilder$MyOptions', 
  'org.apache.hadoop.tools.rumen.TraceBuilder', 
  'org.apache.hadoop.tools.rumen.TreePath', 
  'org.apache.hadoop.tools.rumen.ZombieCluster', 
  'org.apache.hadoop.tools.rumen.ZombieJob', 
  'org.apache.hadoop.tools.rumen.ZombieJobProducer', 
  'org.apache.oro.text.regex.MatchResult', 
  'org.apache.oro.text.regex.Pattern', 
  'org.apache.oro.text.regex.PatternMatcher', 
  'org.apache.oro.text.regex.Perl5Compiler', 
  'org.apache.oro.text.regex.Perl5Matcher', 
  'org.apache.tools.ant.taskdefs.Execute', 
  'org.codehaus.jackson.JsonEncoding', 
  'org.codehaus.jackson.JsonFactory', 
  'org.codehaus.jackson.JsonGenerator', 
  'org.codehaus.jackson.map.ObjectMapper', 
  'org.hsqldb.Server', 
  'org.mockito.AdditionalMatchers', 
  'org.mockito.ArgumentCaptor', 
  'org.mockito.Matchers', 
  'org.mockito.Mockito', 
  'org.mockito.invocation.InvocationOnMock', 
  'org.mockito.stubbing.Answer', 
  'org.mockito.stubbing.OngoingStubbing', 
  'org.mockito.stubbing.Stubber', 
  'org.osgi.framework.Bundle', 
  'org.osgi.framework.BundleActivator', 
  'org.osgi.framework.BundleContext', 
  'org.osgi.framework.BundleEvent', 
  'org.osgi.framework.SynchronousBundleListener',
]
